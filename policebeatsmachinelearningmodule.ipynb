{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Dependencies ##\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read The CSV File ###\n",
    "file = os.path.join('Resources','Crimes_-_2001_to_present.csv')\n",
    "crime_df = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter out the columns that are required alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_columns = ['IUCR', 'Primary Type', 'Arrest', 'Beat',\n",
    "       'District', 'Ward', 'Year', 'Police Districts', 'Police Beats','Latitude', 'Longitude']\n",
    "## Using Loc to filter the required columns \n",
    "chicago_selected_df = crime_df.loc[:, required_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing all the null values and changing the data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop Null Values ##\n",
    "chicago_selected_df = chicago_selected_df.dropna(axis= 0, how = 'any')\n",
    "## Reset Index ##\n",
    "chicago_selected_df.reset_index(drop = True, inplace = True)\n",
    "## Change Datatypes ##\n",
    "chicago_selected_df[['District','Ward','Police Districts','Police Beats']] = chicago_selected_df[['District','Ward','Police Districts','Police Beats']].applymap(np.int64)\n",
    "chicago_selected_df[\"Arrest\"] = chicago_selected_df[\"Arrest\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Outliers by grouping the Data based on Different Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Outliers Based on Primary Type, as in if there are less number of crimes with that crime type remove it\n",
    "chicago_selected_df = chicago_selected_df.groupby(\"Primary Type\").filter(lambda x : len(x)>9500)\n",
    "# Remove Outliers Based on Police Districts, as in if there are less number of crimes within that police district remove it\n",
    "chicago_selected_df = chicago_selected_df.groupby(\"Police Districts\").filter(lambda x : len(x)>1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chicago_2010to2018_df.groupby(\"Primary Type\").count().sort_values(by=\"IUCR\", ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create three subsets - 2018 data for latest info, 2010 to 2018 for training and 2019 for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######   2010 to 2018 data ######\n",
    "chicago_2010to2018_df = chicago_selected_df.loc[(chicago_selected_df['Year'] >= 2010) & (chicago_selected_df['Year'] < 2019), :]\n",
    "chicago_2010to2018_df = chicago_2010to2018_df.sort_values(\"Year\")\n",
    "chicago_2010to2018_df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### 2018 data ######\n",
    "chicago_2018_df = chicago_selected_df.loc[chicago_selected_df['Year'] == 2018, :]\n",
    "chicago_2018_df.reset_index(drop = True, inplace = True)\n",
    "chicago_2018_df.to_csv(\"Chicago2018dataforplots.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### 2019 ######\n",
    "chicago_2019_df = chicago_selected_df.loc[chicago_selected_df['Year'] == 2019, :]\n",
    "chicago_2019_df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enter Machine Learning. Fit, Train, Test, validate and all that Jazz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset in features and target variable\n",
    "feature_cols = ['Primary Type', 'Police Districts', 'Police Beats', 'Ward','Beat']\n",
    "X = chicago_2018_df[feature_cols] # Features\n",
    "y = chicago_2018_df.Arrest # Target variable\n",
    "X = pd.get_dummies(X,columns=[\"Primary Type\"], drop_first=True)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree for Police Beats and districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Algorithm on the required features\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train,y_train)\n",
    "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=10,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Using the test Data and get the confusion matrix \n",
    "predictions = dtree.predict(X_test)\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test,predictions))\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the accuracy of the decision tree model\n",
    "from sklearn import metrics\n",
    "# training metrics\n",
    "print(\"Accuracy: {0:.4f}\".format(metrics.accuracy_score(y_test, predictions)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model Using the training and test Data and get the Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=600)\n",
    "rfc.fit(X_train,y_train)\n",
    "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=600, n_jobs=1,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the cofusion metrics and classification report for this model\n",
    "predictions = rfc.predict(X_test)\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test,predictions))\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the accuracy of the Random Forest model\n",
    "print(\"Accuracy: {0:.4f}\".format(metrics.accuracy_score(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Gaussian Naive Bayes model to fit the training and testing data\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "model = GaussianNB()\n",
    "\n",
    "# Train the model using the training sets\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "#Predict Output\n",
    "y_pred= model.predict(X_test) # 0:Overcast, 2:Mild\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model accuracy for this model\n",
    "from sklearn import metrics\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ready the 2019 data for prediction based on the feature columns of the training and testing data\n",
    "predict_df = chicago_2019_df[:10000]\n",
    "feature_cols = ['Primary Type', 'Police Districts', 'Police Beats', 'Ward','Beat']\n",
    "X_predict = predict_df[feature_cols] # Features\n",
    "X_predict = pd.get_dummies(X_predict,columns=[\"Primary Type\"], drop_first=True)\n",
    "X_predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use the validation data across the three models to get the predictions\n",
    "dtreepredictions = dtree.predict(X_predict)\n",
    "randomforestpredictions = rfc.predict(X_predict)\n",
    "naivepredictions = model.predict(X_predict)\n",
    "predict_df[\"DtreePredict\"] = dtreepredictions\n",
    "predict_df[\"Randomforestpredictions\"] = randomforestpredictions\n",
    "predict_df[\"NaivePredict\"] = naivepredictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df['resultmatch?'] = np.where(predict_df.DtreePredict == predict_df.Arrest, 'True', 'False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df['resultmatch?'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{0:0.2f}% Accuracy achieved by the model\".format(8433/10000 * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
